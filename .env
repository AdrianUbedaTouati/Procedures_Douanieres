# Django
SECRET_KEY=p9cgs2jghxu!gp-&6y7kvk#5i!=^zj-gn)3l&_%f3zt-hfdr1n
DEBUG=False
ALLOWED_HOSTS=vocesalviento.info,www.vocesalviento.info,localhost,127.0.0.1

# LLM Provider - Las API keys se configuran por usuario en su perfil
# No se usan API keys globales en .env

# Email (Console para desarrollo)
EMAIL_BACKEND=django.core.mail.backends.console.EmailBackend
EMAIL_HOST=smtp.gmail.com
EMAIL_PORT=587
EMAIL_USE_TLS=True
EMAIL_HOST_USER=
EMAIL_HOST_PASSWORD=
DEFAULT_FROM_EMAIL=noreply@tenderai.com

# Authentication
EMAIL_VERIFICATION_REQUIRED=False
LOGIN_ATTEMPTS_ENABLED=False
MAX_LOGIN_ATTEMPTS=5
LOGIN_COOLDOWN_MINUTES=30
EMAIL_VERIFICATION_COOLDOWN_SECONDS=120
PASSWORD_RESET_COOLDOWN_SECONDS=120
SITE_URL=https://vocesalviento.info

# ============================================================================
# CONFIGURACIÓN DEL AGENTE RAG
# ============================================================================

# --- Historial de Conversación ---
# Número máximo de mensajes previos a incluir como contexto
# Valores típicos: 5-20. Mayor = más contexto pero más tokens
MAX_CONVERSATION_HISTORY=20

# --- Recuperación de Documentos ---
# Número de documentos a recuperar del vectorstore
DEFAULT_K_RETRIEVE=10

# Umbral mínimo de similaridad (0.0-1.0)
# Mayor = más estricto, solo documentos muy relevantes
MIN_SIMILARITY_SCORE=0.5

# --- LLM Settings ---
# Temperatura para generación de respuestas (0.0-1.0)
# 0.0 = determinista, 1.0 = creativo
LLM_TEMPERATURE=0.3

# Longitud de contexto para Ollama (tokens)
# Valores: 1024, 2048, 4096. Mayor = más memoria RAM
OLLAMA_CONTEXT_LENGTH=4096

# --- Características del Agente ---
# Activar grading de relevancia de documentos
USE_GRADING=True

# Activar verificación XML de campos críticos
USE_XML_VERIFICATION=True

# --- Vectorstore ---
INDEX_TYPE=chromadb
CHROMA_PERSIST_DIRECTORY=data/index/chroma
CHROMA_COLLECTION_NAME=eforms_chunks

# Deshabilitar telemetría anónima de ChromaDB (evita errores en logs)
ANONYMIZED_TELEMETRY=False

# --- Límites de Rendimiento ---
# Timeout para llamadas al LLM (segundos)
LLM_TIMEOUT=360

# Máximo número de iteraciones del agente (evita loops infinitos)
MAX_AGENT_ITERATIONS=10
