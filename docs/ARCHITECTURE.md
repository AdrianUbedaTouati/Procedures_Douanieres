# ğŸ—ï¸ Arquitectura del Sistema TenderAI v3.8.0

**Sistema de Function Calling Multi-Proveedor con BÃºsqueda Iterativa Avanzada**

---

## ğŸ“‹ Ãndice

1. [VisiÃ³n General](#visiÃ³n-general)
2. [Arquitectura de Alto Nivel](#arquitectura-de-alto-nivel)
3. [Estructura de agent_ia_core](#estructura-de-agent_ia_core)
4. [Componentes Principales](#componentes-principales)
5. [Sistema de Tools](#sistema-de-tools)
6. [Sistema de BÃºsqueda Iterativa (NUEVO v3.8)](#sistema-de-bÃºsqueda-iterativa-nuevo-v38)
7. [Sistema de Review y Mejora](#sistema-de-review-y-mejora)
8. [Flujo de Datos Completo](#flujo-de-datos-completo)
9. [Proveedores LLM](#proveedores-llm)
10. [Base de Datos](#base-de-datos)

---

## ğŸ¯ VisiÃ³n General

TenderAI es una plataforma Django que utiliza **Function Calling** para permitir que los LLMs interactÃºen dinÃ¡micamente con datos de licitaciones pÃºblicas mediante **18 tools especializadas**, un **sistema de bÃºsqueda iterativa con verificaciÃ³n de contenido** y un **sistema de auto-mejora** con doble LLM.

### CaracterÃ­sticas Clave v3.8

- âœ… **3 proveedores LLM**: Ollama (local), OpenAI, Google Gemini
- âœ… **18 tools especializadas**: BÃºsqueda iterativa, anÃ¡lisis, web, navegaciÃ³n interactiva
- âœ… **BÃºsqueda iterativa avanzada**: 5 bÃºsquedas secuenciales con verificaciÃ³n de contenido (NUEVO)
- âœ… **VerificaciÃ³n de contenido real**: LLM analiza documentos completos, no solo chunks (NUEVO)
- âœ… **Logging dual completo**: Simple + detallado con 11 mÃ©todos para bÃºsqueda iterativa (NUEVO)
- âœ… **Review Loop automÃ¡tico**: Segunda iteraciÃ³n SIEMPRE ejecutada
- âœ… **Navegador interactivo**: Playwright para sitios JavaScript
- âœ… **Web Search**: Google Custom Search API
- âœ… **Grading y Verification**: Filtrado inteligente de documentos
- âœ… **ChromaDB**: BÃºsqueda vectorial semÃ¡ntica
- âœ… **IteraciÃ³n inteligente**: Hasta 15 pasos para consultas complejas

---

## ğŸ›ï¸ Arquitectura de Alto Nivel

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FRONTEND (Browser)                         â”‚
â”‚                     Bootstrap 5 + JavaScript                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ HTTP/AJAX
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DJANGO APPLICATION                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                      chat/views.py                         â”‚  â”‚
â”‚  â”‚              (ChatMessageCreateView)                       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                  chat/services.py                          â”‚  â”‚
â”‚  â”‚                 (ChatAgentService)                         â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  - Detecta proveedor del usuario                          â”‚  â”‚
â”‚  â”‚  - Crea FunctionCallingAgent                              â”‚  â”‚
â”‚  â”‚  - Ejecuta Review Loop (SIEMPRE)                          â”‚  â”‚
â”‚  â”‚  - Maneja historial conversacional                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚               chat/response_reviewer.py                    â”‚  â”‚
â”‚  â”‚                 (ResponseReviewer)                         â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  - Revisa formato (30%)                                   â”‚  â”‚
â”‚  â”‚  - Revisa contenido (40%)                                 â”‚  â”‚
â”‚  â”‚  - Revisa anÃ¡lisis (30%)                                  â”‚  â”‚
â”‚  â”‚  - Proporciona feedback especÃ­fico                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â†“                                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   AGENT_IA_CORE         â”‚     â”‚   DJANGO ORM            â”‚
â”‚                         â”‚     â”‚                         â”‚
â”‚  FunctionCallingAgent   â”‚â”€â”€â”€â”€â†’â”‚  Tender Model           â”‚
â”‚  ToolRegistry (16)      â”‚     â”‚  CompanyProfile         â”‚
â”‚  SchemaConverter        â”‚     â”‚  ChatMessage            â”‚
â”‚  ResponseReviewer LLM   â”‚     â”‚  User                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”œâ”€â”€â†’ Ollama (localhost:11434)
            â”œâ”€â”€â†’ OpenAI API
            â”œâ”€â”€â†’ Google Gemini API
            â”œâ”€â”€â†’ Google Custom Search API
            â””â”€â”€â†’ Playwright (Chromium)
```

---

## ğŸ“¦ Estructura de agent_ia_core (v3.7.1)

El motor de IA ha sido reorganizado en modulos especializados:

```
agent_ia_core/
â”œâ”€â”€ agent_function_calling.py   # Motor principal del agente
â”œâ”€â”€ config.py                   # Configuracion centralizada
â”œâ”€â”€ prompts_config.py           # CPV codes, NUTS codes, templates
â”‚
â”œâ”€â”€ parser/                     # Parsing y chunking de XMLs
â”‚   â”œâ”€â”€ xml_parser.py           # EFormsXMLParser - parser de eForms
â”‚   â”œâ”€â”€ chunking.py             # EFormsChunker - chunking semantico
â”‚   â””â”€â”€ tools_xml.py            # XmlLookupTool - XPath queries
â”‚
â”œâ”€â”€ prompts/                    # System prompts
â”‚   â””â”€â”€ prompts.py              # SYSTEM_PROMPT, RAG_PROMPT, etc.
â”‚
â”œâ”€â”€ indexing/                   # RAG y vectorizacion
â”‚   â”œâ”€â”€ retriever.py            # HybridRetriever - busqueda vectorial
â”‚   â”œâ”€â”€ index_build.py          # IndexBuilder - construccion de indices
â”‚   â””â”€â”€ ingest.py               # EFormsIngestor - ingesta de datos
â”‚
â”œâ”€â”€ download/                   # Descarga de licitaciones
â”‚   â”œâ”€â”€ descarga_xml.py         # Descarga desde TED API
â”‚   â””â”€â”€ token_tracker.py        # TokenTracker - costos y uso
â”‚
â”œâ”€â”€ engines/                    # Motores especializados
â”‚   â””â”€â”€ recommendation_engine.py # Motor de recomendaciones
â”‚
â”œâ”€â”€ tools/                      # 16 Tools del agente
â”‚   â”œâ”€â”€ registry.py             # ToolRegistry
â”‚   â”œâ”€â”€ base.py                 # BaseTool
â”‚   â”œâ”€â”€ search_tools.py         # find_by_*, search_tenders
â”‚   â”œâ”€â”€ tender_tools.py         # get_tender_*, compare_*
â”‚   â”œâ”€â”€ context_tools.py        # get_company_info, get_tenders_summary
â”‚   â”œâ”€â”€ web_search_tool.py      # Google Custom Search
â”‚   â”œâ”€â”€ browse_tool.py          # browse_webpage
â”‚   â”œâ”€â”€ browse_interactive_tool.py # Playwright navigation
â”‚   â”œâ”€â”€ grading_tool.py         # grade_documents
â”‚   â””â”€â”€ verification_tool.py    # verify_fields
â”‚
â””â”€â”€ schema/                     # Schemas eForms UBL
```

---

## ğŸ§© Componentes Principales

### 1. FunctionCallingAgent

**UbicaciÃ³n**: `agent_ia_core/agent_function_calling.py`

**Responsabilidades**:
- Coordinar la ejecuciÃ³n de tools (16 disponibles)
- Gestionar iteraciones (mÃ¡ximo 15)
- Comunicarse con diferentes proveedores LLM
- Mantener historial conversacional

**MÃ©todos clave**:
```python
class FunctionCallingAgent:
    def __init__(self, llm_provider, llm_model, llm_api_key, retriever, db_session, user):
        # Inicializa LLM segÃºn proveedor
        self.llm = self._create_llm()
        self.tool_registry = ToolRegistry(retriever, db_session, user)
        self.max_iterations = 15

    def query(self, question, conversation_history):
        # Loop de function calling (mÃ¡x 15 iteraciones)
        # 1. LLM decide tools
        # 2. Ejecutar tools
        # 3. LLM procesa resultados
        # 4. Repetir o retornar respuesta
```

### 2. ToolRegistry

**UbicaciÃ³n**: `agent_ia_core/tools/registry.py`

**Responsabilidades**:
- Registrar las 16 tools disponibles
- Convertir schemas al formato del proveedor
- Ejecutar tool calls en paralelo
- Inyectar LLM a tools que lo necesitan

**Tools registradas**:
```python
# Tools de contexto (2)
- get_company_info: InformaciÃ³n de empresa del usuario
- get_tenders_summary: Resumen de licitaciones guardadas

# Tools de bÃºsqueda avanzada (2) - NUEVO v3.8
- find_best_tender: LA mejor licitaciÃ³n (5 bÃºsquedas + verificaciÃ³n)
- find_top_tenders: X mejores licitaciones (5 bÃºsquedas + verificaciÃ³n)

# Tools de bÃºsqueda clÃ¡sica (3)
- search_tenders: BÃºsqueda vectorial ChromaDB
- find_by_budget: Filtrado por presupuesto
- find_by_deadline: Filtrado por fecha
- find_by_cpv: Filtrado por sector
- find_by_location: Filtrado geogrÃ¡fico

# Tools de informaciÃ³n (2)
- get_tender_details: Detalles completos
- get_tender_xml: XML original

# Tools de anÃ¡lisis (2)
- get_statistics: EstadÃ­sticas agregadas
- compare_tenders: ComparaciÃ³n lado a lado

# Tools opcionales (5)
- grade_documents: Filtrado inteligente (opcional)
- verify_fields: VerificaciÃ³n con XML (opcional)
- web_search: Google Custom Search (opcional)
- browse_webpage: ExtracciÃ³n web estÃ¡tica (opcional)
- browse_interactive: Navegador Playwright (opcional)
```

### 3. ResponseReviewer

**UbicaciÃ³n**: `chat/response_reviewer.py`

**Responsabilidades**:
- Revisar respuesta inicial del agente principal
- Evaluar formato, contenido y anÃ¡lisis
- Proporcionar feedback especÃ­fico y constructivo
- Generar score de calidad (0-100)

**Criterios de evaluaciÃ³n**:
```python
FORMATO (30 puntos):
- Â¿Usa Markdown correctamente?
- Â¿Headers ## para mÃºltiples licitaciones?
- Â¿Estructura clara y legible?

CONTENIDO (40 puntos):
- Â¿Responde completamente la pregunta?
- Â¿Incluye todos los datos relevantes?
- Â¿Falta informaciÃ³n importante?

ANÃLISIS (30 puntos):
- Â¿Justifica recomendaciones con datos?
- Â¿Usa documentos correctamente?
- Â¿Es Ãºtil y profesional?
```

**Proceso**:
1. Recibe respuesta inicial + metadata
2. Llama al LLM revisor con prompt especÃ­fico
3. Parsea resultado (status, score, issues, suggestions, feedback)
4. Retorna anÃ¡lisis estructurado

### 4. ChatAgentService (con Review Loop)

**UbicaciÃ³n**: `chat/services.py`

**Responsabilidad**: Orquestar el flujo completo con mejora automÃ¡tica

**Flujo actualizado**:
```python
class ChatAgentService:
    def process_message(self, message, conversation_history):
        # 1. Ejecutar query inicial
        result = agent.query(message, conversation_history)
        response_content = result['answer']

        # 2. REVIEW LOOP (SIEMPRE ejecutado)
        reviewer = ResponseReviewer(agent.llm)
        review_result = reviewer.review_response(
            user_question=message,
            conversation_history=conversation_history,
            initial_response=response_content,
            metadata=result
        )

        # 3. Segunda iteraciÃ³n de mejora (SIEMPRE)
        improvement_prompt = f"""Tu respuesta fue revisada.

        Respuesta original: {response_content}

        Problemas: {review_result['issues']}
        Sugerencias: {review_result['suggestions']}
        Feedback: {review_result['feedback']}

        Genera una respuesta MEJORADA con acceso completo a tools."""

        improved_result = agent.query(
            improvement_prompt,
            conversation_history + [
                {'role': 'user', 'content': message},
                {'role': 'assistant', 'content': response_content}
            ]
        )

        # 4. Merge resultados de ambas iteraciones
        final_response = improved_result['answer']
        final_documents = result['documents'] + improved_result['documents']

        return final_response, final_documents, review_metadata
```

### 5. Retriever (ChromaDB)

**UbicaciÃ³n**: `agent_ia_core/retriever.py`

**Responsabilidad**: BÃºsqueda vectorial semÃ¡ntica

```python
class HybridRetriever:
    def __init__(self, provider, api_key, embedding_model, k):
        self.embeddings = self._create_embeddings(provider, api_key, embedding_model)
        self.vectorstore = Chroma(
            collection_name="eforms_chunks",
            embedding_function=self.embeddings,
            persist_directory="data/index/chroma"
        )

    def retrieve(self, query, filters=None, k=None):
        results = self.vectorstore.similarity_search_with_score(
            query, k=k, filter=filters
        )
        return self._format_results(results)
```

---

## ğŸ” Sistema de BÃºsqueda Iterativa (NUEVO v3.8)

â­ **BÃºsqueda iterativa con verificaciÃ³n de contenido** - Sistema avanzado que realiza 5 bÃºsquedas secuenciales optimizadas, verifica contenido completo y selecciona los mejores resultados con justificaciÃ³n del LLM.

### Componentes del Sistema

#### 1. LLM Intermediario (Query Optimization)
**Responsabilidad**: Generar queries optimizadas para cada iteraciÃ³n

```python
# Prompt al LLM intermediario
"""Eres un experto en optimizaciÃ³n de bÃºsquedas semÃ¡nticas.

CONTEXTO DISPONIBLE:
- Perfil de empresa: {company_info}
- Historial conversacional: {conversation_history}
- Tool calls previas: {tool_calls_history}

QUERY ORIGINAL: "{original_query}"

BÃšSQUEDAS PREVIAS:
- BÃºsqueda 1: query="...", resultado={doc_id, chunk_count, score}
- BÃºsqueda 2: query="...", resultado={doc_id, chunk_count, score}

Genera una query optimizada para BÃšSQUEDA 3/5 con un enfoque diferente.
Responde SOLO con la query."""
```

#### 2. Semantic Search (ChromaDB)
**Responsabilidad**: Buscar top-7 chunks mÃ¡s relevantes

```python
from agent_ia_core.tools.auxiliary.search_base import semantic_search_single

result = semantic_search_single(
    query=optimized_query,
    vectorstore=retriever,
    k=7
)
# Retorna: {success, document: {id, chunk_count, metadata, best_score}}
```

#### 3. Document Retrieval (get_tender_details)
**Responsabilidad**: Obtener documento completo, no solo chunks

```python
tender_details = get_tender_details(tender_id=doc_id, user=user)
# Retorna: tÃ­tulo, descripciÃ³n completa, presupuesto, plazos, etc.
```

#### 4. Content Verification (LLM Verifier)
**Responsabilidad**: Analizar si el contenido REALMENTE corresponde

```python
# Prompt al LLM verificador
"""Usuario busca: "{original_query}"

Documento encontrado:
- Chunk_count: {chunk_count} (1=poco fiable, 2=fiable, 3+=muy fiable)

CONTENIDO COMPLETO:
ID: {tender_id}
TÃ­tulo: {title}
DescripciÃ³n: {description}
Comprador: {buyer}
CPV: {cpv_codes}
UbicaciÃ³n: {nuts_regions}
Presupuesto: {budget_eur} EUR
Fecha lÃ­mite: {tender_deadline_date}

Â¿Este documento REALMENTE corresponde a lo que busca el usuario?

Responde en formato JSON:
{
  "corresponds": true/false,
  "score": 0-10,
  "reasoning": "explicaciÃ³n breve",
  "missing_info": "quÃ© falta (null si todo OK)"
}
"""
```

#### 5. Final Selection (LLM Selector)
**Responsabilidad**: Seleccionar el/los mejor(es) documento(s)

```python
# Prompt al LLM selector
"""Has completado 5 bÃºsquedas secuenciales. AquÃ­ estÃ¡ el resumen:

- BÃºsqueda 1: doc_A - Chunks: 3, Corresponde: true, PuntuaciÃ³n: 9/10
- BÃºsqueda 2: doc_B - Chunks: 2, Corresponde: false, PuntuaciÃ³n: 4/10
- BÃºsqueda 3: doc_A - Chunks: 5, Corresponde: true, PuntuaciÃ³n: 9/10
- BÃºsqueda 4: doc_C - Chunks: 4, Corresponde: true, PuntuaciÃ³n: 7/10
- BÃºsqueda 5: doc_A - Chunks: 5, Corresponde: true, PuntuaciÃ³n: 9/10

Selecciona {"EL MEJOR" if mode == "single" else f"LOS {limit} MEJORES"}.

CRITERIOS:
1. Mayor puntuaciÃ³n LLM (verificaciÃ³n de contenido)
2. Mayor chunk_count (relevancia semÃ¡ntica)
3. Apariciones mÃºltiples = mÃ¡s confiable
4. Documentos con "corresponds: true"

Responde en formato JSON:
{
  "selected_document_ids": ["doc_A"],
  "reasoning": "doc_A apareciÃ³ 3 veces con puntuaciÃ³n alta...",
  "is_reliable": true,
  "clarification_request": null,
  "confidence_score": 0.95
}
"""
```

### Flujo Completo de BÃºsqueda Iterativa

```
find_best_tender(query="licitaciÃ³n software IA")
â”‚
â”œâ”€ FASE 1: CONTEXTO
â”‚  â”œâ”€ get_company_info() â†’ perfil empresa
â”‚  â”œâ”€ conversation_history â†’ Ãºltimos mensajes
â”‚  â””â”€ tool_calls_history â†’ tools usadas
â”‚
â”œâ”€ FASE 2: 5 BÃšSQUEDAS SECUENCIALES
â”‚  â”‚
â”‚  â”œâ”€ BÃšSQUEDA 1:
â”‚  â”‚  â”œâ”€ LLM genera query: "desarrollo software inteligencia artificial"
â”‚  â”‚  â”œâ”€ semantic_search_single() â†’ doc_A (3 chunks, score 0.89)
â”‚  â”‚  â”œâ”€ get_tender_details(doc_A) â†’ contenido completo
â”‚  â”‚  â”œâ”€ LLM verifica: corresponds=true, score=9/10
â”‚  â”‚  â””â”€ Feedback: "âœ“ Buen resultado"
â”‚  â”‚
â”‚  â”œâ”€ BÃšSQUEDA 2:
â”‚  â”‚  â”œâ”€ LLM genera query diferente: "machine learning deep learning"
â”‚  â”‚  â”œâ”€ semantic_search_single() â†’ doc_B (2 chunks, score 0.82)
â”‚  â”‚  â”œâ”€ get_tender_details(doc_B) â†’ contenido completo
â”‚  â”‚  â”œâ”€ LLM verifica: corresponds=false, score=4/10
â”‚  â”‚  â””â”€ Feedback: "âœ— Resultado dÃ©bil"
â”‚  â”‚
â”‚  â”œâ”€ BÃšSQUEDA 3:
â”‚  â”‚  â”œâ”€ LLM genera query: "sistema inteligente anÃ¡lisis datos"
â”‚  â”‚  â”œâ”€ semantic_search_single() â†’ doc_A (5 chunks, score 0.92)
â”‚  â”‚  â”œâ”€ get_tender_details(doc_A) â†’ contenido completo
â”‚  â”‚  â”œâ”€ LLM verifica: corresponds=true, score=9/10
â”‚  â”‚  â””â”€ Feedback: "âœ“ Mismo doc, mejor chunk_count"
â”‚  â”‚
â”‚  â”œâ”€ BÃšSQUEDA 4: ... â†’ doc_C (4 chunks, score=7/10)
â”‚  â”‚
â”‚  â””â”€ BÃšSQUEDA 5: ... â†’ doc_A (5 chunks, score=9/10)
â”‚
â””â”€ FASE 3: SELECCIÃ“N FINAL
   â”œâ”€ AnÃ¡lisis de resultados:
   â”‚  - doc_A: 3 apariciones, chunk_count [3, 5, 5], score promedio 9/10
   â”‚  - doc_B: 1 apariciÃ³n, chunk_count [2], score 4/10
   â”‚  - doc_C: 1 apariciÃ³n, chunk_count [4], score 7/10
   â”‚
   â”œâ”€ LLM selecciona: doc_A
   â”‚  - RazÃ³n: "ApareciÃ³ 3 veces con puntuaciÃ³n consistente 9/10"
   â”‚  - Confianza: 0.95
   â”‚  - Fiable: true
   â”‚
   â””â”€ Retorna: {
        success: true,
        result: {id: doc_A, ...},
        search_metrics: {
          iterations: 5,
          unique_docs: 3,
          best_doc_appearances: 3,
          chunk_progression: [3, 5, 5],
          confidence: 0.95
        }
      }
```

### Sistema de Logging Dual

**UbicaciÃ³n**: `apps/core/logging_config.py`

**11 nuevos mÃ©todos** para logging completo:

1. `log_iterative_search_start()` - Inicio con contexto
2. `log_search_iteration_start()` - Inicio de cada iteraciÃ³n
3. `log_query_optimization()` - Query optimizada por LLM
4. `log_semantic_search()` - Resultados de ChromaDB
5. `log_document_retrieval()` - Documento completo
6. `log_content_verification()` - VerificaciÃ³n por LLM
7. `log_iteration_feedback()` - Feedback para prÃ³xima
8. `log_iteration_result()` - Resultado completo
9. `log_final_selection()` - SelecciÃ³n final
10. `log_iterative_search_end()` - Fin con mÃ©tricas
11. `log_fallback_search()` - BÃºsqueda de respaldo

**Doble archivo de log**:
- `*_simple.log`: Trazas concisas (funciones, parÃ¡metros clave)
- `*_detailed.log`: JSON completo (prompts, respuestas raw, metadata)

Ver [LOGGING_SYSTEM.md](LOGGING_SYSTEM.md) para detalles.

---

## ğŸ› ï¸ Sistema de Tools

### CategorizaciÃ³n Completa (18 Tools)

#### ğŸ¢ Tools de Contexto (2)
**DescripciÃ³n**: InformaciÃ³n especÃ­fica del usuario

1. **get_company_info**: Perfil de empresa del usuario
2. **get_tenders_summary**: Resumen de licitaciones guardadas

**ActivaciÃ³n**: AutomÃ¡tica si hay usuario autenticado

#### ğŸ” Tools de BÃºsqueda Avanzada (2) - NUEVO v3.8
**DescripciÃ³n**: BÃºsqueda iterativa con verificaciÃ³n de contenido

3. **find_best_tender**: LA mejor licitaciÃ³n (5 bÃºsquedas + verificaciÃ³n)
4. **find_top_tenders**: X mejores licitaciones (5 bÃºsquedas + verificaciÃ³n)

**ActivaciÃ³n**: Siempre disponibles

#### ğŸ” Tools de BÃºsqueda ClÃ¡sica (3)
**DescripciÃ³n**: BÃºsqueda y filtrado tradicional

5. **search_tenders**: BÃºsqueda vectorial semÃ¡ntica (ChromaDB)
6. **find_by_budget**: Filtrado por rango de presupuesto (SQL)
7. **find_by_deadline**: Filtrado por fecha lÃ­mite (SQL)
8. **find_by_cpv**: Filtrado por sector CPV (ChromaDB)
9. **find_by_location**: Filtrado geogrÃ¡fico NUTS (ChromaDB)

**ActivaciÃ³n**: Siempre disponibles

#### ğŸ“„ Tools de InformaciÃ³n (2)
**DescripciÃ³n**: Detalles completos de licitaciones

8. **get_tender_details**: InformaciÃ³n completa desde DB
9. **get_tender_xml**: XML original completo

**ActivaciÃ³n**: Siempre disponibles

#### ğŸ“Š Tools de AnÃ¡lisis (2)
**DescripciÃ³n**: EstadÃ­sticas y comparaciones

10. **get_statistics**: EstadÃ­sticas agregadas
11. **compare_tenders**: ComparaciÃ³n lado a lado (2-5 licitaciones)

**ActivaciÃ³n**: Siempre disponibles

#### ğŸ¯ Tools de Calidad (2 - Opcionales)
**DescripciÃ³n**: Mejora de resultados

12. **grade_documents**: Filtrado inteligente de documentos irrelevantes
13. **verify_fields**: VerificaciÃ³n de campos crÃ­ticos con XML

**ActivaciÃ³n**: `use_grading=True`, `use_verification=True` en User model

#### ğŸŒ Tools de Web (3 - Opcionales)
**DescripciÃ³n**: BÃºsqueda e interacciÃ³n web

14. **web_search**: Google Custom Search API
15. **browse_webpage**: ExtracciÃ³n HTML estÃ¡tica (requests + BeautifulSoup)
16. **browse_interactive**: Navegador con Playwright (JavaScript, clicks, formularios)

**ActivaciÃ³n**:
- `use_web_search=True` + Google API credentials
- `browse_interactive` requiere Playwright instalado

---

## ğŸ”„ Sistema de Review y Mejora

### Flujo Completo del Review Loop

```
1. ITERACIÃ“N INICIAL
   Usuario: "Dame las mejores licitaciones de software"
   â†“
   Agent ejecuta tools â†’ Genera respuesta inicial
   â†“

2. REVIEW (SIEMPRE ejecutado)
   ResponseReviewer analiza:
   - Formato: Â¿Usa ## para cada licitaciÃ³n?
   - Contenido: Â¿Incluye presupuestos, plazos?
   - AnÃ¡lisis: Â¿Justifica por quÃ© son las "mejores"?
   â†“
   Resultado: {
     status: "NEEDS_IMPROVEMENT" / "APPROVED",
     score: 75,
     issues: ["Falta justificaciÃ³n de por quÃ© son mejores"],
     suggestions: ["Agregar anÃ¡lisis de fit con perfil usuario"],
     feedback: "Explica por quÃ© cada licitaciÃ³n es adecuada"
   }
   â†“

3. SEGUNDA ITERACIÃ“N (SIEMPRE ejecutada)
   Prompt mejorado:
   "Tu respuesta inicial: [...]
    Problemas: [...]
    Sugerencias: [...]

    Genera respuesta MEJORADA con acceso a tools"
   â†“
   Agent ejecuta tools nuevamente si necesita â†’ Genera respuesta mejorada
   â†“

4. MERGE Y RETORNO
   - Response final: respuesta mejorada
   - Documents: docs iteraciÃ³n 1 + docs iteraciÃ³n 2
   - Tools used: union de ambas iteraciones
   - Metadata: incluye info de review
```

### Metadata de Review

```python
{
    'review': {
        'review_performed': True,
        'review_status': 'NEEDS_IMPROVEMENT',
        'review_score': 75,
        'review_issues': ['Falta X', 'Falta Y'],
        'review_suggestions': ['Agregar Z'],
        'improvement_applied': True
    }
}
```

---

## ğŸ”„ Flujo de Datos Completo

### Usuario hace pregunta: "Busca licitaciones de IT > 50k con review"

```
1. FRONTEND
   JavaScript â†’ POST /chat/<session_id>/message/

2. DJANGO VIEWS
   ChatMessageCreateView
   â†’ Guarda mensaje usuario
   â†’ Llama ChatAgentService.process_message()

3. CHATAGENTSERVICE - ITERACIÃ“N 1
   â†’ Crea FunctionCallingAgent
   â†’ Ejecuta agent.query()

4. FUNCTIONCALLINGAGENT - ITERACIÃ“N 1
   Paso 1: LLM decide tools
   â†’ "Voy a usar find_by_cpv('IT') y find_by_budget(min=50000)"

   Paso 2: ToolRegistry ejecuta
   â†’ find_by_cpv â†’ 10 licitaciones IT
   â†’ find_by_budget â†’ 8 licitaciones >50k

   Paso 3: LLM genera respuesta inicial
   â†’ "EncontrÃ© 3 licitaciones que cumplen ambos criterios..."

   Retorna: {answer, documents, tools_used, iterations}

5. CHATAGENTSERVICE - REVIEW
   â†’ Crea ResponseReviewer(llm)
   â†’ reviewer.review_response()

6. RESPONSEREVIEWER
   â†’ Llama LLM con prompt de revisiÃ³n
   â†’ Analiza formato, contenido, anÃ¡lisis
   â†’ Retorna: {status, score, issues, suggestions, feedback}

7. CHATAGENTSERVICE - ITERACIÃ“N 2 (SIEMPRE)
   â†’ Construye improvement_prompt
   â†’ Ejecuta agent.query(improvement_prompt)

8. FUNCTIONCALLINGAGENT - ITERACIÃ“N 2
   Paso 1: LLM lee feedback
   â†’ "Necesito agregar anÃ¡lisis de por quÃ© son las mejores"
   â†’ "Voy a usar get_company_info() para contexto"

   Paso 2: Ejecuta get_company_info
   â†’ Perfil de empresa del usuario

   Paso 3: LLM genera respuesta mejorada
   â†’ "BasÃ¡ndome en tu perfil de empresa...
      estas son las mejores porque:
      1. LicitaciÃ³n X - match 95% con tu experiencia..."

   Retorna: {answer mejorado, documents nuevos, tools_used}

9. CHATAGENTSERVICE - MERGE
   â†’ Response final = respuesta mejorada
   â†’ Documents = docs iter1 + docs iter2
   â†’ Tools used = union
   â†’ Metadata incluye review tracking

10. DJANGO VIEWS
    â†’ Guarda ChatMessage con respuesta final
    â†’ Retorna JSON al frontend

11. FRONTEND
    â†’ Renderiza respuesta mejorada
    â†’ Muestra metadata (review score, tools usadas)
```

---

## ğŸ¤– Proveedores LLM

### Ollama (Local)

**ComunicaciÃ³n**:
```python
import ollama

response = ollama.chat(
    model='qwen2.5:7b',
    messages=messages,
    tools=tool_registry.get_ollama_tools()
)
```

**Ventajas**:
- ğŸ†“ Gratis
- ğŸ”’ 100% local (privacidad)
- âš¡ Sin latencia de red

**Desventajas**:
- ğŸ’» Requiere recursos (16GB+ RAM)
- ğŸ¯ Calidad depende del modelo

### OpenAI (Cloud)

**ComunicaciÃ³n**:
```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model='gpt-4o-mini', api_key=api_key)
llm_with_tools = llm.bind_tools(tool_registry.get_openai_tools())
response = llm_with_tools.invoke(messages)
```

**Ventajas**:
- ğŸ¯ Alta calidad
- âš¡ RÃ¡pido
- ğŸ“Š Excelente en consultas complejas

**Desventajas**:
- ğŸ’° Costo por token
- â˜ï¸ Datos en cloud

### Google Gemini (Cloud)

**ComunicaciÃ³n**:
```python
from langchain_google_genai import ChatGoogleGenerativeAI

llm = ChatGoogleGenerativeAI(model='gemini-2.0-flash-exp', api_key=api_key)
llm_with_tools = llm.bind_tools(tool_registry.get_gemini_tools())
response = llm_with_tools.invoke(messages)
```

**Ventajas**:
- ğŸ’° MÃ¡s econÃ³mico que OpenAI
- âš¡ Muy rÃ¡pido
- ğŸ¯ Buena calidad

**Desventajas**:
- ğŸ’° Costo por token
- â˜ï¸ Datos en cloud

---

## ğŸ’¾ Base de Datos

### Modelos Django

#### User (authentication/models.py)
```python
class User(AbstractUser):
    # Basic
    email = EmailField(unique=True)

    # LLM Config
    llm_provider = CharField(max_length=50)  # 'ollama', 'openai', 'google'
    llm_api_key = TextField(blank=True)
    ollama_model = CharField(max_length=100)
    openai_model = CharField(max_length=100)  # Nuevo campo

    # Features
    use_function_calling = BooleanField(default=True)
    use_grading = BooleanField(default=False)
    use_verification = BooleanField(default=False)
    use_web_search = BooleanField(default=False)

    # Google Custom Search (para web_search)
    google_search_api_key = TextField(blank=True)
    google_search_engine_id = CharField(max_length=100, blank=True)

    # Browse settings
    browse_max_chars = IntegerField(default=10000)
    browse_chunk_size = IntegerField(default=1250)
```

#### Tender (tenders/models.py)
```python
class Tender(Model):
    ojs_notice_id = CharField(max_length=255, unique=True)
    title = TextField()
    description = TextField(blank=True)
    buyer_name = CharField(max_length=500)
    budget_amount = DecimalField(max_digits=15, decimal_places=2, null=True)
    currency = CharField(max_length=3, null=True)
    tender_deadline_date = DateField(null=True)
    cpv_codes = JSONField(default=list)
    nuts_regions = JSONField(default=list)
    source_path = CharField(max_length=500, blank=True)
```

#### ChatMessage (chat/models.py)
```python
class ChatMessage(Model):
    session = ForeignKey(ChatSession, on_delete=CASCADE)
    role = CharField(max_length=20)  # 'user', 'assistant'
    content = TextField()
    timestamp = DateTimeField(auto_now_add=True)
    metadata = JSONField(default=dict)  # Incluye review tracking
```

### ChromaDB

**ColecciÃ³n**: `eforms_chunks`
**Documentos**: 235+ chunks

**Metadata por documento**:
```python
{
    'ojs_notice_id': '00668461-2025',
    'section': 'object_description',
    'title': 'Desarrollo de software',
    'buyer_name': 'Ministerio',
    'cpv_codes': ['72000000'],
    'nuts_regions': ['ES300'],
    'budget_amount': 961200.0,
    'budget_eur': '961200.0',  # String para filtros
    'tender_deadline_date': '2025-09-15'
}
```

---

## ğŸ“Š MÃ©tricas de Rendimiento

### Latencia con Review Loop

| OperaciÃ³n | Ollama | OpenAI | Gemini |
|-----------|--------|--------|--------|
| **IteraciÃ³n 1** | 500-1000ms | 800-1500ms | 600-1200ms |
| **Review** | 200-400ms | 300-600ms | 200-500ms |
| **IteraciÃ³n 2** | 500-1000ms | 800-1500ms | 600-1200ms |
| **Total** | 1.2-2.4s | 1.9-3.6s | 1.4-2.9s |

### Consumo de Recursos

| Proveedor | RAM | CPU | Disco | Red |
|-----------|-----|-----|-------|-----|
| **Ollama** | 8-16GB | Alto | 5-10GB | No |
| **OpenAI** | < 500MB | Bajo | MÃ­nimo | SÃ­ |
| **Gemini** | < 500MB | Bajo | MÃ­nimo | SÃ­ |

---

## ğŸ”— Referencias

- **CÃ³digo fuente**: `agent_ia_core/`, `chat/`
- **Tools**: [TOOLS_REFERENCE.md](TOOLS_REFERENCE.md)
- **Flujo completo**: [FLUJO_EJECUCION_CHAT.md](FLUJO_EJECUCION_CHAT.md)
- **ConfiguraciÃ³n**: [CONFIGURACION_AGENTE.md](CONFIGURACION_AGENTE.md)
- **Changelog**: [CHANGELOG.md](CHANGELOG.md)

---

**VersiÃ³n**: 3.8.0
**Ãšltima actualizaciÃ³n**: 2025-12-02
**Features destacadas**: BÃºsqueda iterativa con verificaciÃ³n, Review Loop automÃ¡tico, 18 tools

**ğŸ¤– Generated with [Claude Code](https://claude.com/claude-code)**

**Co-Authored-By: Claude <noreply@anthropic.com>**
